{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T15:17:55.374396Z",
     "start_time": "2026-01-27T15:17:53.043475Z"
    }
   },
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "df = pd.read_csv(\"../data/recipes.csv\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.columns)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "def preprocess_instructions(instructions):\n",
    "    try:  #remove the square brackets and quotation marks, separate at commas\n",
    "        instructions = instructions.strip(\"[]\").replace(\"'\", \"\").split(', ')\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    cleaned_tokens = []\n",
    "    for item in instructions:\n",
    "        text = item.lower()  #lowercase\n",
    "        text = re.sub(r'[\\d½¾¼⅓⅔⅛⅜⅝⅞]+', '', text)  #remove numbers, fraction symbols\n",
    "        text = re.sub(r'[^a-z\\s]', ' ', text)  #replace everything that is not a letter with a space\n",
    "\n",
    "        tokens = text.split()\n",
    "        for token in tokens:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            if len(lemma) > 2:\n",
    "                cleaned_tokens.append(lemma)\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
      "       'Cleaned_Ingredients'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:05.693755Z",
     "start_time": "2026-01-27T15:17:55.400321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "print(\"start preprocessing\")\n",
    "\n",
    "#create processed instructions row in dataset (saved in ram)\n",
    "df['instructions_processed'] = df['Instructions'].apply(preprocess_instructions)\n",
    "\n",
    "print(\"finished preprocessing for recipes\")\n",
    "\n",
    "#reset index, for id´s even is we got the C1 in the dataset\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#gensim needs the taggedoc, doesn´t work with the id or C1 from pandas\n",
    "print(\"create taggeddocuments\")\n",
    "tagged_data = [\n",
    "    TaggedDocument(words=row['instructions_processed'], tags=[str(i)])\n",
    "    for i, row in df.iterrows()\n",
    "]\n",
    "\n",
    "print(f\"   -> {len(tagged_data)} recipes prepared\")\n"
   ],
   "id": "e84d715ef8cf78a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preprocessing\n",
      "finished preprocessing for recipes\n",
      "create taggeddocuments\n",
      "   -> 13501 recipes prepared\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:24.366747Z",
     "start_time": "2026-01-27T15:18:06.372193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(\"Cores:\", cores)\n",
    "print(df.columns)\n",
    "\n",
    "print(\"Initialize Doc2Vec Model\")\n",
    "model = Doc2Vec(vector_size=150, window=5, min_count=5, dm=1, epochs=10, workers=cores - 4)\n",
    "\n",
    "#count the words, create structure\n",
    "model.build_vocab(tagged_data)\n",
    "print(\"created vocabulary\")\n",
    "\n",
    "print(\"start training\")\n",
    "#train with the tagged data, recipe counts and the iterations\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n"
   ],
   "id": "1d663907e3ef8e1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores: 20\n",
      "Index(['Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
      "       'Cleaned_Ingredients', 'instructions_processed'],\n",
      "      dtype='object')\n",
      "Initialize Doc2Vec Model\n",
      "created vocabulary\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:24.477239Z",
     "start_time": "2026-01-27T15:18:24.373782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"../data/models\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "recipe_model_path = os.path.join(folder_path, \"doc2vec.model\")\n",
    "model.save(recipe_model_path)\n",
    "print(f\"model saved to {recipe_model_path}\")\n",
    "\n",
    "pkl_path = os.path.join(folder_path, \"recipe_vectors.pkl\")\n",
    "\n",
    "recipe_vectors = {\n",
    "    i: model.dv[str(i)]\n",
    "    for i in range(len(df))\n",
    "}\n",
    "\n",
    "#wb -> write binary\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump(recipe_vectors, f)\n",
    "\n",
    "    print(f\"saved vector database{pkl_path}\")"
   ],
   "id": "3de239b9376210c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ../data/models\\doc2vec.model\n",
      "saved vector database../data/models\\recipe_vectors.pkl\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:27.361568Z",
     "start_time": "2026-01-27T15:18:24.603763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MEAT_KEYWORDS = ['chicken', 'beef', 'pork', 'steak', 'fish', 'salmon', 'shrimp', 'bacon', 'ham', 'sausage', 'meat', 'tuna', 'cod', 'lamb', 'turkey', 'duck', 'clam', 'oyster', 'mussel', 'anchovy', 'anchovies', 'crab', 'lobster', 'salami', 'prosciutto', 'pancetta', 'guanciale', 'soppressata', 'chorizo', 'pepperoni', 'bass' ]\n",
    "NUT_KEYWORDS = ['nut', 'peanut', 'almond', 'cashew', 'walnut', 'pecan', 'hazelnut', 'pistachio']\n",
    "DAIRY_KEYWORDS = ['milk', 'cheese', 'cream', 'butter', 'yogurt', 'whey', 'casein', 'ghee', 'mozzarella',\n",
    "    'parmesan', 'ricotta', 'mascarpone', 'feta', 'lactose']\n",
    "\n",
    "\n",
    "def detect_dietary_tags(row):\n",
    "    text = (str(row['Title']) + \" \" + str(row['Ingredients'])).lower()\n",
    "\n",
    "    tags = {}\n",
    "\n",
    "    #vegetarian?\n",
    "    has_meat = any(meat in text for meat in MEAT_KEYWORDS)\n",
    "    tags['is_vegetarian'] = not has_meat\n",
    "\n",
    "    #vegan (no meat und no milk/egg)\n",
    "    has_dairy = any(dairy in text for dairy in DAIRY_KEYWORDS)\n",
    "    has_egg = 'egg' in text\n",
    "    tags['is_vegan'] = not has_meat and not has_dairy and not has_egg\n",
    "\n",
    "    tags['has_nuts'] = any(nut in text for nut in NUT_KEYWORDS)\n",
    "\n",
    "    return pd.Series(tags)\n",
    "\n",
    "\n",
    "\n",
    "dietary_cols = df.apply(detect_dietary_tags, axis=1)\n",
    "df = pd.concat([df, dietary_cols], axis=1)\n",
    "\n",
    "print(df[['Title', 'is_vegetarian']].head(3))\n",
    "print(df[['Title', 'has_nuts']].head(3))\n"
   ],
   "id": "35ec849ec8641bae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  is_vegetarian\n",
      "0  Miso-Butter Roast Chicken With Acorn Squash Pa...          False\n",
      "1                    Crispy Salt and Pepper Potatoes           True\n",
      "2                        Thanksgiving Mac and Cheese           True\n",
      "                                               Title  has_nuts\n",
      "0  Miso-Butter Roast Chicken With Acorn Squash Pa...     False\n",
      "1                    Crispy Salt and Pepper Potatoes     False\n",
      "2                        Thanksgiving Mac and Cheese     False\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:27.472295Z",
     "start_time": "2026-01-27T15:18:27.394566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_id = 100\n",
    "\n",
    "title_original = df.iloc[test_id]['Title']\n",
    "\n",
    "print(f\"search similarity #{test_id}: '{title_original}'\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "sims = model.dv.most_similar(str(test_id), topn=5)\n",
    "\n",
    "for doc_id, score in sims:\n",
    "    idx = int(doc_id)\n",
    "    title = df.iloc[idx]['Title']\n",
    "    print(f\"Score: {score:.3f} | ID: {idx} | {title}\")"
   ],
   "id": "60bfb7b1ba53424a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search similarity #100: 'Stuffed Eggplants and Zucchini in a Rich Tomato Sauce (Baatingan w Kusaa Bil Banadoura)'\n",
      "--------------------------------------------------\n",
      "Score: 0.608 | ID: 769 | Kimchi and Miso Noodle Soup\n",
      "Score: 0.604 | ID: 7652 | Meatballs: The Spuntino Way\n",
      "Score: 0.587 | ID: 2866 | Jollof Rice\n",
      "Score: 0.579 | ID: 1751 | Roast Chicken Thighs with Veggies\n",
      "Score: 0.563 | ID: 533 | Long-Roasted Eggplant with Garlic, Labne, and Tiny Chile Croutons\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:27.518854Z",
     "start_time": "2026-01-27T15:18:27.480235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"load recipe vectors\")\n",
    "folder_path = \"../data/models\"\n",
    "file_path = os.path.join(folder_path, \"recipe_vectors.pkl\")\n",
    "\n",
    "#rb -> read binary\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_vectors = pickle.load(f)\n",
    "\n",
    "        print(f\"loaded vectors from {file_path}\")\n",
    "\n",
    "    test_idx = 100\n",
    "    vector = loaded_vectors[test_idx]\n",
    "\n",
    "    print(f\"check for recipe id: {test_idx}:\")\n",
    "    print(f\" - Typ: {type(vector)}\")\n",
    "    print(f\" - Windowsize: {vector.shape}\")\n",
    "    print(f\" - first 5 values: {vector[:5]}\")\n",
    "\n",
    "\n"
   ],
   "id": "3866ef0a41fd365f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load recipe vectors\n",
      "loaded vectors from ../data/models\\recipe_vectors.pkl\n",
      "check for recipe id: 100:\n",
      " - Typ: <class 'numpy.ndarray'>\n",
      " - Windowsize: (150,)\n",
      " - first 5 values: [-0.4523666   0.3887053  -0.41205233  0.2968251  -0.27696124]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T15:18:27.582632Z",
     "start_time": "2026-01-27T15:18:27.537635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "print(df.columns)\n",
    "rows = ['Title',\n",
    "        'Ingredients',\n",
    "        'Instructions',\n",
    "        'Image_Name',\n",
    "        'is_vegetarian',\n",
    "        'is_vegan',\n",
    "        'has_nuts'\n",
    "        ]\n",
    "df_metadata = df[rows].copy()\n",
    "\n",
    "path = \"../data/models/metadata.pkl\"\n",
    "\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(df_metadata, f)\n",
    "\n",
    "    print(\"loaded metadata\")\n",
    "\n",
    "    print(df_metadata.head())"
   ],
   "id": "40a59821bf987521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
      "       'Cleaned_Ingredients', 'instructions_processed', 'is_vegetarian',\n",
      "       'is_vegan', 'has_nuts'],\n",
      "      dtype='object')\n",
      "loaded metadata\n",
      "                                               Title  \\\n",
      "0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
      "1                    Crispy Salt and Pepper Potatoes   \n",
      "2                        Thanksgiving Mac and Cheese   \n",
      "3                 Italian Sausage and Bread Stuffing   \n",
      "4                                       Newton's Law   \n",
      "\n",
      "                                         Ingredients  \\\n",
      "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n",
      "1  ['2 large egg whites', '1 pound new potatoes (...   \n",
      "2  ['1 cup evaporated milk', '1 cup whole milk', ...   \n",
      "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...   \n",
      "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...   \n",
      "\n",
      "                                        Instructions  \\\n",
      "0  Pat chicken dry with paper towels, season all ...   \n",
      "1  Preheat oven to 400°F and line a rimmed baking...   \n",
      "2  Place a rack in middle of oven; preheat to 400...   \n",
      "3  Preheat oven to 350°F with rack in middle. Gen...   \n",
      "4  Stir together brown sugar and hot water in a c...   \n",
      "\n",
      "                                          Image_Name  is_vegetarian  is_vegan  \\\n",
      "0  miso-butter-roast-chicken-acorn-squash-panzanella          False     False   \n",
      "1         crispy-salt-and-pepper-potatoes-dan-kluger           True     False   \n",
      "2         thanksgiving-mac-and-cheese-erick-williams           True     False   \n",
      "3          italian-sausage-and-bread-stuffing-240559          False     False   \n",
      "4                 newtons-law-apple-bourbon-cocktail           True     False   \n",
      "\n",
      "   has_nuts  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
