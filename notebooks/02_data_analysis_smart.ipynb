{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-25T16:22:24.518856Z",
     "start_time": "2025-11-25T16:22:21.734938Z"
    }
   },
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/recipes.csv\")\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "smart_stopwords = set(stopwords.words('english')).union({\n",
    "    \"cup\", \"cups\", \"teaspoon\", \"tablespoon\", \"ounce\", \"pound\", \"gram\", \"slice\", \"can\", \"jar\", \"package\", \"pinch\", \"dash\", \"clove\", \"large\", \"medium\", \"small\", \"fresh\", \"dry\", \"chopped\", \"ground\", \"patted\", \"quality\", \"kosher\", \"virgin\", \"sun\", \"taste\", \"room\", \"temperature\", \"part\", \"accompaniment\", \"thermometer\",\n",
    "})\n",
    "\n",
    "def preprocess_ingredients_smart(ingredients_list_str):\n",
    "\n",
    "    try:\n",
    "        if isinstance(ingredients_list_str, str):\n",
    "            ingredients = ingredients_list_str.strip(\"[]\").replace(\"'\", \"\").split(', ')\n",
    "        elif isinstance(ingredients_list_str, list):\n",
    "            ingredients = ingredients_list_str\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    cleaned_tokens = []\n",
    "    for item in ingredients:\n",
    "        text = item.lower()\n",
    "        text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "        text = re.sub(r'[\\d½¾¼⅓⅔⅛⅜⅝⅞]+', '', text)\n",
    "        text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tagged_tokens = nltk.pos_tag(tokens)\n",
    "\n",
    "        for word, tag in tagged_tokens:\n",
    "            if tag.startswith('NN'):\n",
    "                lemma = lemmatizer.lemmatize(word)\n",
    "                if lemma not in smart_stopwords and len(lemma) > 2:\n",
    "                    cleaned_tokens.append(lemma)\n",
    "\n",
    "    return cleaned_tokens"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T16:22:25.239817Z",
     "start_time": "2025-11-25T16:22:24.788518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"../data/recipes.csv\")\n",
    "    print(\"✅ Daten erfolgreich geladen!\")\n",
    "    print(f\"Datensatz hat {df.shape[0]} Zeilen und {df.shape[1]} Spalten.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ FEHLER: Die CSV-Datei wurde nicht gefunden. Bitte Pfad überprüfen.\")"
   ],
   "id": "fddd5c5931ecd57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Daten erfolgreich geladen!\n",
      "Datensatz hat 13501 Zeilen und 6 Spalten.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T16:23:39.911697Z",
     "start_time": "2025-11-25T16:22:25.255810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starte smartes Preprocessing mit POS-Tagging...\")\n",
    "\n",
    "df['ingredients_smart'] = df['Ingredients'].apply(preprocess_ingredients_smart)\n",
    "\n",
    "print(\"✅ Smartes Preprocessing abgeschlossen!\")\n",
    "\n",
    "# --- Zeige ein Beispiel, um das Ergebnis zu prüfen ---\n",
    "print(\"\\n--- Beispiel-Ergebnis des smarten Preprocessing ---\")\n",
    "for i in range(3):\n",
    "    print(f\"RAW: {df['Ingredients'].iloc[i][:100]}...\") # Nur die ersten 100 Zeichen\n",
    "    print(f\"SMART: {df['ingredients_smart'].iloc[i]}\")\n",
    "    print(\"-\" * 20)"
   ],
   "id": "41351e05f88e0d1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte smartes Preprocessing mit POS-Tagging...\n",
      "✅ Smartes Preprocessing abgeschlossen!\n",
      "\n",
      "--- Beispiel-Ergebnis des smarten Preprocessing ---\n",
      "RAW: ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher salt, divided, plus more', '2 small acorn squash (abo...\n",
      "SMART: ['chicken', 'tsp', 'salt', 'acorn', 'squash', 'tbsp', 'sage', 'tbsp', 'tbsp', 'butter', 'tsp', 'allspice', 'pepper', 'flake', 'pepper', 'bread', 'piece', 'apple', 'cut', 'piece', 'tbsp', 'oil', 'onion', 'tbsp', 'apple', 'cider', 'vinegar', 'miso', 'flour', 'tbsp', 'butter', 'wine', 'broth', 'miso', 'salt', 'pepper']\n",
      "--------------------\n",
      "RAW: ['2 large egg whites', '1 pound new potatoes (about 1 inch in diameter)', '2 teaspoons kosher salt',...\n",
      "SMART: ['egg', 'white', 'potato', 'salt', 'pepper', 'thyme', 'parsley']\n",
      "--------------------\n",
      "RAW: ['1 cup evaporated milk', '1 cup whole milk', '1 tsp. garlic powder', '1 tsp. onion powder', '1 tsp....\n",
      "SMART: ['milk', 'milk', 'tsp', 'powder', 'onion', 'powder', 'tsp', 'paprika', 'tsp', 'pepper', 'tsp', 'salt', 'cheddar', 'fat', 'cream', 'cheese', 'elbow', 'macaroni']\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T16:23:41.086375Z",
     "start_time": "2025-11-25T16:23:39.975371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import Phrases\n",
    "\n",
    "print(\"Starte Training des Bigramm-Modells...\")\n",
    "\n",
    "# Trainiere das Phrases-Modell auf den neuen, smarten Daten\n",
    "phrases_model_smart = Phrases(df['ingredients_smart'], min_count=5, threshold=0.1, scoring=\"npmi\")\n",
    "bigram_model_smart = Phraser(phrases_model_smart)\n",
    "\n",
    "# Wende das Bigramm-Modell an\n",
    "df['ingredients_bigrams_smart'] = df['ingredients_smart'].apply(lambda tokens: bigram_model_smart[tokens])\n",
    "\n",
    "print(\"✅ Bigramm-Modell trainiert und angewendet!\")\n",
    "\n",
    "# --- Zeige ein Beispiel für die Bigramm-Erkennung ---\n",
    "print(\"\\n--- Beispiel für erkannte Bigramme ---\")\n",
    "# Finde ein paar Beispiele, wo sich etwas geändert hat\n",
    "for i in range(len(df)):\n",
    "    if df['ingredients_smart'].iloc[i] != df['ingredients_bigrams_smart'].iloc[i]:\n",
    "        print(f\"Vorher: {df['ingredients_smart'].iloc[i]}\")\n",
    "        print(f\"Nachher: {df['ingredients_bigrams_smart'].iloc[i]}\")\n",
    "        print(\"-\" * 30)\n",
    "        break # Zeige nur das erste Beispiel"
   ],
   "id": "e74c42f5b7f5342f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Training des Bigramm-Modells...\n",
      "✅ Bigramm-Modell trainiert und angewendet!\n",
      "\n",
      "--- Beispiel für erkannte Bigramme ---\n",
      "Vorher: ['chicken', 'tsp', 'salt', 'acorn', 'squash', 'tbsp', 'sage', 'tbsp', 'tbsp', 'butter', 'tsp', 'allspice', 'pepper', 'flake', 'pepper', 'bread', 'piece', 'apple', 'cut', 'piece', 'tbsp', 'oil', 'onion', 'tbsp', 'apple', 'cider', 'vinegar', 'miso', 'flour', 'tbsp', 'butter', 'wine', 'broth', 'miso', 'salt', 'pepper']\n",
      "Nachher: ['chicken', 'tsp_salt', 'acorn', 'squash', 'tbsp', 'sage', 'tbsp', 'tbsp_butter', 'tsp_allspice', 'pepper_flake', 'pepper', 'bread', 'piece', 'apple_cut', 'piece', 'tbsp_oil', 'onion', 'tbsp', 'apple_cider', 'vinegar_miso', 'flour', 'tbsp_butter', 'wine', 'broth', 'miso', 'salt_pepper']\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T16:23:42.940703Z",
     "start_time": "2025-11-25T16:23:41.122760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"Starte finales Word2Vec-Training...\")\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Trainiere das Word2Vec-Modell auf den smarten Bigrammen\n",
    "model_smart = Word2Vec(df['ingredients_bigrams_smart'],\n",
    "                       workers=cores-1,\n",
    "                       vector_size=150, # Erhöhen wir mal die Vektorgröße für potenziell bessere Ergebnisse\n",
    "                       window=10,       # und das Fenster\n",
    "                       min_count=5,\n",
    "                       sg=1)           # Skip-Gram\n",
    "\n",
    "# Erstelle den Ordner, falls er nicht existiert\n",
    "os.makedirs(\"../data/models\", exist_ok=True)\n",
    "\n",
    "# Speichere das Modell unter einem neuen, klaren Namen\n",
    "model_path_smart = \"../data/models/recipe_word2vec_smart.model\"\n",
    "model_smart.save(model_path_smart)\n",
    "\n",
    "print(f\"✅ Smartes Modell trainiert und gespeichert unter: {model_path_smart}\")"
   ],
   "id": "ce3e271756b50f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte finales Word2Vec-Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Smartes Modell trainiert und gespeichert unter: ../data/models/recipe_word2vec_smart.model\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T16:23:43.100519Z",
     "start_time": "2025-11-25T16:23:42.988477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lade das gerade gespeicherte Modell, um sicherzugehen, dass alles geklappt hat\n",
    "loaded_model_smart = Word2Vec.load(model_path_smart)\n",
    "\n",
    "def check_smart(term, model):\n",
    "    \"\"\"Eine Funktion, um die Ähnlichkeit von Wörtern zu prüfen.\"\"\"\n",
    "    try:\n",
    "        similar = model.wv.most_similar(term, topn=5)\n",
    "        print(f\"\\nAlternativen zu '{term}' (SMART-MODELL):\")\n",
    "        for item, score in similar:\n",
    "            print(f\"  -> {item} ({score:.2f})\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n❌ '{term}' kenne ich im smarten Modell nicht.\")\n",
    "\n",
    "# Teste das Modell mit relevanten Begriffen\n",
    "check_smart(\"chicken\", loaded_model_smart)\n",
    "check_smart(\"beef\", loaded_model_smart)\n",
    "check_smart(\"chocolate\", loaded_model_smart)\n",
    "check_smart(\"spaghetti\", loaded_model_smart)\n",
    "check_smart(\"tomato\", loaded_model_smart) # Teste ein Bigramm!\n",
    "check_smart(\"oil\", loaded_model_smart)     # Und noch eins!"
   ],
   "id": "8a68f6a557f0cada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternativen zu 'chicken' (SMART-MODELL):\n",
      "  -> breast (0.86)\n",
      "  -> leg_thigh (0.86)\n",
      "  -> wing (0.85)\n",
      "  -> bone (0.84)\n",
      "  -> neck (0.84)\n",
      "\n",
      "Alternativen zu 'beef' (SMART-MODELL):\n",
      "  -> tomato_sauce (0.93)\n",
      "  -> turkey (0.91)\n",
      "  -> beef_chuck (0.90)\n",
      "  -> beef_pork (0.89)\n",
      "  -> onion_stalk (0.89)\n",
      "\n",
      "Alternativen zu 'chocolate' (SMART-MODELL):\n",
      "  -> bittersweet_chocolate (0.96)\n",
      "  -> milk_chocolate (0.95)\n",
      "  -> bittersweet_semisweet (0.95)\n",
      "  -> semisweet_bittersweet (0.95)\n",
      "  -> bar (0.95)\n",
      "\n",
      "Alternativen zu 'spaghetti' (SMART-MODELL):\n",
      "  -> pasta_salt (0.96)\n",
      "  -> bucatini (0.95)\n",
      "  -> penne (0.95)\n",
      "  -> soppressata (0.94)\n",
      "  -> rigatoni (0.94)\n",
      "\n",
      "Alternativen zu 'tomato' (SMART-MODELL):\n",
      "  -> oregano (0.91)\n",
      "  -> eggplant (0.91)\n",
      "  -> onion_tomato (0.87)\n",
      "  -> oregano_pepper (0.87)\n",
      "  -> cheese_mozzarella (0.87)\n",
      "\n",
      "Alternativen zu 'oil' (SMART-MODELL):\n",
      "  -> pepper_oil (0.77)\n",
      "  -> oil_salt (0.77)\n",
      "  -> togarashi (0.76)\n",
      "  -> parsley_mint (0.76)\n",
      "  -> paprika_powder (0.75)\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
