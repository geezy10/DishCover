{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T11:18:02.948030Z",
     "start_time": "2025-12-23T11:18:01.716157Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_FOLDER = os.path.join(\"..\", \"data\", \"images\", \"Food Images\")\n",
    "\n",
    "if os.path.exists(IMG_FOLDER):\n",
    "    print(\"Images folder exists\")\n",
    "    print(f\"Anzahl: {len(os.listdir(IMG_FOLDER))}\")\n",
    "    df = pd.read_csv(\"../data/recipes.csv\")\n",
    "    print(\"✅ Daten erfolgreich geladen!\")\n",
    "else:\n",
    "    print(\"Images folder doesn't exist\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images folder exists\n",
      "Anzahl: 13582\n",
      "✅ Daten erfolgreich geladen!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:18:08.643038Z",
     "start_time": "2025-12-23T11:18:02.952897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(\"start Preprocessing...\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "measurements = {\n",
    "    \"cup\", \"cups\", \"ts\", \"tsp\", \"teaspoon\", \"tbsp\", \"tablespoon\",\n",
    "    \"oz\", \"ounce\", \"lb\", \"pound\", \"g\", \"gram\", \"kg\", \"ml\", \"l\", \"liter\",\n",
    "    \"pinch\", \"dash\", \"slice\", \"can\", \"jar\", \"package\",\n",
    "    \"large\", \"small\", \"medium\", \"whole\", \"inch\", \"diameter\", \"total\",\n",
    "    \"stick\", \"full\", \"piece\", \"rotisserie\", \"roast\", \"roasted\", \"grilled\", \"baked\",\n",
    "    \"wing\", \"breast\", \"thigh\", \"leg\", \"bone\", \"boneless\", \"skinless\", \"skin\",\n",
    "    \"lean\", \"chuck\", \"sirloin\", \"ground\", \"minced\", \"pint\", \"quart\", \"gallon\",\n",
    "    \"drumstick\", \"drumsticks\", \"drumette\", \"drumettes\", \"ripe\", \"ripened\", \"chunk\"\n",
    "}\n",
    "\n",
    "cooking_methods = {\n",
    "    \"chopped\", \"diced\", \"minced\", \"sliced\", \"grated\", \"peeled\", \"cored\",\n",
    "    \"finely\", \"coarsely\", \"freshly\", \"ground\", \"divided\", \"plus\", \"more\",\n",
    "    \"unsalted\", \"salted\", \"taste\", \"room\", \"temperature\", \"melted\", \"softened\",\n",
    "    \"cut\", \"shredded\", \"cooked\", \"high\", \"low\", \"medium\", \"exceed\", \"stuffed\", \"stuffing\",\n",
    "    \"patted\"\n",
    "}\n",
    "\n",
    "other_stopwords = {\n",
    "    \"gala\", \"pink\", \"lady\", \"new\", \"extra\", \"sharp\", \"fat\", \"new\", \"extra\",\n",
    "    \"sharp\", \"virgin\", \"good\", \"quality\", \"sturdy\", \"torn\", \"storebought\",\n",
    "    \"homemade\", \"removed\", \"casing\", \"semisweet\", \"bittersweet\", \"unsweetened\",\n",
    "    \"halved\", \"quartered\", \"pitted\", \"cured\", \"brine\", \"preserved\",\n",
    "    \"sun\", \"dried\", \"vine\", \"ripened\", \"wafer\", \"chip\", \"chips\", \"short\", \"long\",\n",
    "    \"preferably\", \"optional\", \"garnish\", \"about\", \"lindt\", \"perugina\", \"ghirardelli\",\n",
    "    \"attached\", \"flat\", \"fed\", \"grass\", \"drained\", \"tiny\", \"seasoning\", \"picholine\", \"cerignola\",\n",
    "    \"dry\", \"fresh\", \"frozen\", \"canned\"}\n",
    "\n",
    "all_stopwords = set(stopwords_list).union(measurements).union(cooking_methods).union(other_stopwords)\n",
    "\n",
    "\n",
    "def preprocess_ingredients(ingredients):\n",
    "    try:  #remove the square brackets and quotation marks, separate at commas\n",
    "        ingredients = ingredients.strip(\"[]\").replace(\"'\", \"\").split(', ')\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    cleaned_tokens = []\n",
    "    for item in ingredients:\n",
    "        text = item.lower()  #lowercase\n",
    "        text = re.sub(r'[\\d½¾¼⅓⅔⅛⅜⅝⅞]+', '', text)  #remove numbers, fraction symbols\n",
    "        text = re.sub(r'[^a-z\\s]', ' ', text)  #replace everything that is not a letter with a space\n",
    "\n",
    "        tokens = text.split()\n",
    "        for token in tokens:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            if lemma not in all_stopwords and len(lemma) > 2:\n",
    "                cleaned_tokens.append(lemma)\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "df['ingredients_for_w2v'] = df['Ingredients'].apply(preprocess_ingredients)\n",
    "\n",
    "print(\"✅ Preprocessing abgeschlossen!\")\n",
    "\n",
    "# --- Finaler Test ---\n",
    "print(\"\\n--- Visueller Vergleich nach neuer Bereinigung ---\")\n",
    "for i in range(3):\n",
    "    print(f\"RAW:     {df['Ingredients'].iloc[i]}\")\n",
    "    print(f\"NEU:     {df['ingredients_for_w2v'].iloc[i]}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "\n"
   ],
   "id": "43c3b5f9215ac5bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Preprocessing...\n",
      "✅ Preprocessing abgeschlossen!\n",
      "\n",
      "--- Visueller Vergleich nach neuer Bereinigung ---\n",
      "RAW:     ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher salt, divided, plus more', '2 small acorn squash (about 3 lb. total)', '2 Tbsp. finely chopped sage', '1 Tbsp. finely chopped rosemary', '6 Tbsp. unsalted butter, melted, plus 3 Tbsp. room temperature', '¼ tsp. ground allspice', 'Pinch of crushed red pepper flakes', 'Freshly ground black pepper', '⅓ loaf good-quality sturdy white bread, torn into 1\" pieces (about 2½ cups)', '2 medium apples (such as Gala or Pink Lady; about 14 oz. total), cored, cut into 1\" pieces', '2 Tbsp. extra-virgin olive oil', '½ small red onion, thinly sliced', '3 Tbsp. apple cider vinegar', '1 Tbsp. white miso', '¼ cup all-purpose flour', '2 Tbsp. unsalted butter, room temperature', '¼ cup dry white wine', '2 cups unsalted chicken broth', '2 tsp. white miso', 'Kosher salt, freshly ground pepper']\n",
      "NEU:     ['chicken', 'kosher', 'salt', 'acorn', 'squash', 'sage', 'rosemary', 'butter', 'allspice', 'crushed', 'red', 'pepper', 'flake', 'black', 'pepper', 'loaf', 'white', 'bread', 'apple', 'olive', 'oil', 'red', 'onion', 'thinly', 'apple', 'cider', 'vinegar', 'white', 'miso', 'purpose', 'flour', 'butter', 'white', 'wine', 'chicken', 'broth', 'white', 'miso', 'kosher', 'salt', 'pepper']\n",
      "--------------------\n",
      "RAW:     ['2 large egg whites', '1 pound new potatoes (about 1 inch in diameter)', '2 teaspoons kosher salt', '¾ teaspoon finely ground black pepper', '1 teaspoon finely chopped rosemary', '1 teaspoon finely chopped thyme', '1 teaspoon finely chopped parsley']\n",
      "NEU:     ['egg', 'white', 'potato', 'kosher', 'salt', 'black', 'pepper', 'rosemary', 'thyme', 'parsley']\n",
      "--------------------\n",
      "RAW:     ['1 cup evaporated milk', '1 cup whole milk', '1 tsp. garlic powder', '1 tsp. onion powder', '1 tsp. smoked paprika', '½ tsp. freshly ground black pepper', '1 tsp. kosher salt, plus more', '2 lb. extra-sharp cheddar, coarsely grated', '4 oz. full-fat cream cheese', '1 lb. elbow macaroni']\n",
      "NEU:     ['evaporated', 'milk', 'milk', 'garlic', 'powder', 'onion', 'powder', 'smoked', 'paprika', 'black', 'pepper', 'kosher', 'salt', 'cheddar', 'cream', 'cheese', 'elbow', 'macaroni']\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:18:09.681596Z",
     "start_time": "2025-12-23T11:18:08.832704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "print(\"start bigramm modell...\")\n",
    "common_suffixes = {\"powder\", \"oil\", \"sauce\", \"cheese\", \"cream\", \"milk\", \"butter\"}\n",
    "phrases_model = Phrases(df['ingredients_for_w2v'], min_count=5, threshold=0.2,\n",
    "                        scoring=\"npmi\")  #Combinations that apppear less then 5 times will be ignored (min)\n",
    "bigram_model = Phraser(phrases_model)  #phraser takes only the neccessary parts, smaller in the ram as above\n",
    "\n",
    "\n",
    "def apply_bigrams(tokens):\n",
    "    return bigram_model[tokens]\n",
    "\n",
    "\n",
    "df['ingredients_bigrams'] = df['ingredients_for_w2v'].apply(apply_bigrams)\n",
    "\n",
    "print(\"\\n--- Vorher / Nachher Vergleich ---\")\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    alt = df['ingredients_for_w2v'].iloc[i]\n",
    "    neu = df['ingredients_bigrams'].iloc[i]\n",
    "\n",
    "    if alt != neu:\n",
    "        print(f\"Alt: {alt}\")\n",
    "        print(f\"Neu: {neu}\")\n",
    "        print(\"-\" * 30)\n",
    "        count += 1\n",
    "        if count >= 5: break\n",
    "\n"
   ],
   "id": "761b0250de55babc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start bigramm modell...\n",
      "\n",
      "--- Vorher / Nachher Vergleich ---\n",
      "Alt: ['chicken', 'kosher', 'salt', 'acorn', 'squash', 'sage', 'rosemary', 'butter', 'allspice', 'crushed', 'red', 'pepper', 'flake', 'black', 'pepper', 'loaf', 'white', 'bread', 'apple', 'olive', 'oil', 'red', 'onion', 'thinly', 'apple', 'cider', 'vinegar', 'white', 'miso', 'purpose', 'flour', 'butter', 'white', 'wine', 'chicken', 'broth', 'white', 'miso', 'kosher', 'salt', 'pepper']\n",
      "Neu: ['chicken', 'kosher_salt', 'acorn_squash', 'sage_rosemary', 'butter', 'allspice', 'crushed_red', 'pepper_flake', 'black_pepper', 'loaf', 'white_bread', 'apple', 'olive_oil', 'red_onion', 'thinly', 'apple_cider', 'vinegar', 'white_miso', 'purpose_flour', 'butter', 'white_wine', 'chicken_broth', 'white_miso', 'kosher_salt', 'pepper']\n",
      "------------------------------\n",
      "Alt: ['egg', 'white', 'potato', 'kosher', 'salt', 'black', 'pepper', 'rosemary', 'thyme', 'parsley']\n",
      "Neu: ['egg_white', 'potato', 'kosher_salt', 'black_pepper', 'rosemary_thyme', 'parsley']\n",
      "------------------------------\n",
      "Alt: ['evaporated', 'milk', 'milk', 'garlic', 'powder', 'onion', 'powder', 'smoked', 'paprika', 'black', 'pepper', 'kosher', 'salt', 'cheddar', 'cream', 'cheese', 'elbow', 'macaroni']\n",
      "Neu: ['evaporated_milk', 'milk', 'garlic_powder', 'onion', 'powder', 'smoked_paprika', 'black_pepper', 'kosher_salt', 'cheddar', 'cream_cheese', 'elbow_macaroni']\n",
      "------------------------------\n",
      "Alt: ['round', 'italian', 'loaf', 'cube', 'olive', 'oil', 'sweet', 'italian', 'sausage', 'butter', 'onion', 'celery', 'rib', 'garlic', 'clove', 'egg', 'lightly', 'beaten', 'heavy', 'cream', 'turkey', 'giblet', 'stock', 'reduced', 'sodium', 'chicken', 'broth', 'parmigiano', 'reggiano', 'leaf', 'parsley', 'shallow', 'ceramic', 'glass', 'baking', 'dish']\n",
      "Neu: ['round', 'italian_loaf', 'cube', 'olive_oil', 'sweet_italian', 'sausage', 'butter', 'onion_celery', 'rib', 'garlic_clove', 'egg_lightly', 'beaten', 'heavy_cream', 'turkey_giblet', 'stock_reduced', 'sodium_chicken', 'broth', 'parmigiano_reggiano', 'leaf_parsley', 'shallow', 'ceramic_glass', 'baking_dish']\n",
      "------------------------------\n",
      "Alt: ['dark', 'brown', 'sugar', 'hot', 'water', 'bourbon', 'lemon', 'juice', 'apple', 'butter', 'orange', 'twist', 'cinnamon']\n",
      "Neu: ['dark_brown', 'sugar', 'hot_water', 'bourbon', 'lemon_juice', 'apple', 'butter', 'orange_twist', 'cinnamon']\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3e52be8759e6a3af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:18:10.960851Z",
     "start_time": "2025-12-23T11:18:09.699600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "print(\"start final word2vec training\")\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = Word2Vec(df['ingredients_bigrams'], workers=cores - 1, vector_size=200, window=10, min_count=5, sg=1)\n",
    "\n",
    "model_path = \"../data/models/recipe_word2vec.model\"\n",
    "#model.save(model_path)\n",
    "print(f\"model trained and saved under: {model_path}\")\n"
   ],
   "id": "23e51dfe3f4a7919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start final word2vec training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and saved under: ../data/models/recipe_word2vec.model\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:26:25.247526Z",
     "start_time": "2025-12-23T11:26:25.233887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def check(term):\n",
    "    try:\n",
    "        similar = model.wv.most_similar(term, topn=5)\n",
    "        print(f\"\\nAlternativen zu '{term}'?\")\n",
    "        for item, score in similar:\n",
    "            print(f\"  -> {item} ({score:.2f})\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n❌ '{term}' kenne ich nicht.\")\n",
    "\n",
    "# Teste die neuen Bigrams!\n",
    "check(\"chicken\")\n",
    "check(\"beef\")\n",
    "check(\"chocolate\")\n",
    "check(\"spaghetti\")\n",
    "check(\"tomato\")\n",
    "check(\"olive\")"
   ],
   "id": "95f707cf4fff0b30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Title', 'Ingredients', 'Instructions', 'Image_Name',\n",
      "       'Cleaned_Ingredients', 'ingredients_for_w2v', 'ingredients_bigrams'],\n",
      "      dtype='object')\n",
      "\n",
      "Alternativen zu 'chicken'?\n",
      "  -> chicken_turkey (0.81)\n",
      "  -> cajun (0.81)\n",
      "  -> dark_meat (0.80)\n",
      "  -> top_round (0.79)\n",
      "  -> poultry (0.78)\n",
      "\n",
      "Alternativen zu 'beef'?\n",
      "  -> hot_spanish (0.85)\n",
      "  -> slab (0.85)\n",
      "  -> pork (0.84)\n",
      "  -> paprika_hot (0.84)\n",
      "  -> bottle_dark (0.84)\n",
      "\n",
      "Alternativen zu 'chocolate'?\n",
      "  -> milk_chocolate (0.94)\n",
      "  -> white_chocolate (0.92)\n",
      "  -> dark_chocolate (0.90)\n",
      "  -> chocolate_cacao (0.90)\n",
      "  -> bar (0.90)\n",
      "\n",
      "Alternativen zu 'spaghetti'?\n",
      "  -> rigatoni (0.94)\n",
      "  -> capellini (0.93)\n",
      "  -> bucatini (0.93)\n",
      "  -> accompaniment_parmigiano (0.93)\n",
      "  -> pecorino (0.92)\n",
      "\n",
      "Alternativen zu 'tomato'?\n",
      "  -> undrained (0.80)\n",
      "  -> piquillo_pepper (0.79)\n",
      "  -> san_marzano (0.78)\n",
      "  -> grape_cherry (0.77)\n",
      "  -> tomato_seeded (0.77)\n",
      "\n",
      "Alternativen zu 'olive'?\n",
      "  -> kalamata (0.85)\n",
      "  -> caper (0.81)\n",
      "  -> spanish (0.80)\n",
      "  -> kalamata_olive (0.79)\n",
      "  -> marinated_artichoke (0.77)\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
