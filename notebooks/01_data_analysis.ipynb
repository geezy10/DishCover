{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-13T14:21:23.664365Z",
     "start_time": "2025-12-13T14:21:22.388928Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_FOLDER = os.path.join(\"..\", \"data\", \"images\", \"Food Images\")\n",
    "\n",
    "if os.path.exists(IMG_FOLDER):\n",
    "    print(\"Images folder exists\")\n",
    "    print(f\"Anzahl: {len(os.listdir(IMG_FOLDER))}\")\n",
    "    df = pd.read_csv(\"../data/recipes.csv\")\n",
    "    print(\"✅ Daten erfolgreich geladen!\")\n",
    "else:\n",
    "    print(\"Images folder doesn't exist\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images folder exists\n",
      "Anzahl: 13582\n",
      "✅ Daten erfolgreich geladen!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:21:29.178871Z",
     "start_time": "2025-12-13T14:21:23.672995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(\"start Preprocessing...\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "measurements = {\n",
    "    \"cup\", \"cups\", \"ts\", \"tsp\", \"teaspoon\", \"tbsp\", \"tablespoon\",\n",
    "    \"oz\", \"ounce\", \"lb\", \"pound\", \"g\", \"gram\", \"kg\", \"ml\", \"l\", \"liter\",\n",
    "    \"pinch\", \"dash\", \"slice\", \"can\", \"jar\", \"package\",\n",
    "    \"large\", \"small\", \"medium\", \"whole\", \"inch\", \"diameter\", \"total\",\n",
    "    \"stick\", \"full\", \"piece\", \"rotisserie\", \"roast\", \"roasted\", \"grilled\", \"baked\",\n",
    "    \"wing\", \"breast\", \"thigh\", \"leg\", \"bone\", \"boneless\", \"skinless\", \"skin\",\n",
    "    \"lean\", \"chuck\", \"sirloin\", \"ground\", \"minced\", \"pint\", \"quart\", \"gallon\",\n",
    "    \"drumstick\", \"drumsticks\", \"drumette\", \"drumettes\", \"ripe\", \"ripened\", \"chunk\"\n",
    "}\n",
    "\n",
    "cooking_methods = {\n",
    "    \"chopped\", \"diced\", \"minced\", \"sliced\", \"grated\", \"peeled\", \"cored\",\n",
    "    \"finely\", \"coarsely\", \"freshly\", \"ground\", \"divided\", \"plus\", \"more\",\n",
    "    \"unsalted\", \"salted\", \"taste\", \"room\", \"temperature\", \"melted\", \"softened\",\n",
    "    \"cut\", \"shredded\", \"cooked\", \"high\", \"low\", \"medium\", \"exceed\", \"stuffed\", \"stuffing\",\n",
    "    \"patted\"\n",
    "}\n",
    "\n",
    "other_stopwords = {\n",
    "    \"gala\", \"pink\", \"lady\", \"new\", \"extra\", \"sharp\", \"fat\", \"new\", \"extra\",\n",
    "    \"sharp\", \"virgin\", \"good\", \"quality\", \"sturdy\", \"torn\", \"storebought\",\n",
    "    \"homemade\", \"removed\", \"casing\", \"semisweet\", \"bittersweet\", \"unsweetened\",\n",
    "    \"halved\", \"quartered\", \"pitted\", \"cured\", \"brine\", \"preserved\",\n",
    "    \"sun\", \"dried\", \"vine\", \"ripened\", \"wafer\", \"chip\", \"chips\", \"short\", \"long\",\n",
    "    \"preferably\", \"optional\", \"garnish\", \"about\", \"lindt\", \"perugina\", \"ghirardelli\",\n",
    "    \"attached\", \"flat\", \"fed\", \"grass\", \"drained\", \"tiny\", \"seasoning\", \"picholine\", \"cerignola\",\n",
    "    \"dry\", \"fresh\", \"frozen\", \"canned\"}\n",
    "\n",
    "all_stopwords = set(stopwords_list).union(measurements).union(cooking_methods).union(other_stopwords)\n",
    "\n",
    "\n",
    "def preprocess_ingredients(ingredients):\n",
    "    try:  #remove the square brackets and quotation marks, separate at commas\n",
    "        ingredients = ingredients.strip(\"[]\").replace(\"'\", \"\").split(', ')\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    cleaned_tokens = []\n",
    "    for item in ingredients:\n",
    "        text = item.lower()  #lowercase\n",
    "        text = re.sub(r'[\\d½¾¼⅓⅔⅛⅜⅝⅞]+', '', text)  #remove numbers, fraction symbols\n",
    "        text = re.sub(r'[^a-z\\s]', ' ', text)  #replace everything that is not a letter with a space\n",
    "\n",
    "        tokens = text.split()\n",
    "        for token in tokens:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            if lemma not in all_stopwords and len(lemma) > 2:\n",
    "                cleaned_tokens.append(lemma)\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "df['ingredients_for_w2v'] = df['Ingredients'].apply(preprocess_ingredients)\n",
    "\n",
    "print(\"✅ Preprocessing abgeschlossen!\")\n",
    "\n",
    "# --- Finaler Test ---\n",
    "print(\"\\n--- Visueller Vergleich nach neuer Bereinigung ---\")\n",
    "for i in range(3):\n",
    "    print(f\"RAW:     {df['Ingredients'].iloc[i]}\")\n",
    "    print(f\"NEU:     {df['ingredients_for_w2v'].iloc[i]}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "\n"
   ],
   "id": "43c3b5f9215ac5bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Preprocessing...\n",
      "✅ Preprocessing abgeschlossen!\n",
      "\n",
      "--- Visueller Vergleich nach neuer Bereinigung ---\n",
      "RAW:     ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher salt, divided, plus more', '2 small acorn squash (about 3 lb. total)', '2 Tbsp. finely chopped sage', '1 Tbsp. finely chopped rosemary', '6 Tbsp. unsalted butter, melted, plus 3 Tbsp. room temperature', '¼ tsp. ground allspice', 'Pinch of crushed red pepper flakes', 'Freshly ground black pepper', '⅓ loaf good-quality sturdy white bread, torn into 1\" pieces (about 2½ cups)', '2 medium apples (such as Gala or Pink Lady; about 14 oz. total), cored, cut into 1\" pieces', '2 Tbsp. extra-virgin olive oil', '½ small red onion, thinly sliced', '3 Tbsp. apple cider vinegar', '1 Tbsp. white miso', '¼ cup all-purpose flour', '2 Tbsp. unsalted butter, room temperature', '¼ cup dry white wine', '2 cups unsalted chicken broth', '2 tsp. white miso', 'Kosher salt, freshly ground pepper']\n",
      "NEU:     ['chicken', 'kosher', 'salt', 'acorn', 'squash', 'sage', 'rosemary', 'butter', 'allspice', 'crushed', 'red', 'pepper', 'flake', 'black', 'pepper', 'loaf', 'white', 'bread', 'apple', 'olive', 'oil', 'red', 'onion', 'thinly', 'apple', 'cider', 'vinegar', 'white', 'miso', 'purpose', 'flour', 'butter', 'white', 'wine', 'chicken', 'broth', 'white', 'miso', 'kosher', 'salt', 'pepper']\n",
      "--------------------\n",
      "RAW:     ['2 large egg whites', '1 pound new potatoes (about 1 inch in diameter)', '2 teaspoons kosher salt', '¾ teaspoon finely ground black pepper', '1 teaspoon finely chopped rosemary', '1 teaspoon finely chopped thyme', '1 teaspoon finely chopped parsley']\n",
      "NEU:     ['egg', 'white', 'potato', 'kosher', 'salt', 'black', 'pepper', 'rosemary', 'thyme', 'parsley']\n",
      "--------------------\n",
      "RAW:     ['1 cup evaporated milk', '1 cup whole milk', '1 tsp. garlic powder', '1 tsp. onion powder', '1 tsp. smoked paprika', '½ tsp. freshly ground black pepper', '1 tsp. kosher salt, plus more', '2 lb. extra-sharp cheddar, coarsely grated', '4 oz. full-fat cream cheese', '1 lb. elbow macaroni']\n",
      "NEU:     ['evaporated', 'milk', 'milk', 'garlic', 'powder', 'onion', 'powder', 'smoked', 'paprika', 'black', 'pepper', 'kosher', 'salt', 'cheddar', 'cream', 'cheese', 'elbow', 'macaroni']\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:21:30.085058Z",
     "start_time": "2025-12-13T14:21:29.336045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "print(\"start bigramm modell...\")\n",
    "common_suffixes = {\"powder\", \"oil\", \"sauce\", \"cheese\", \"cream\", \"milk\", \"butter\"}\n",
    "phrases_model = Phrases(df['ingredients_for_w2v'], min_count=5, threshold=0.2,\n",
    "                        scoring=\"npmi\")  #Combinations that apppear less then 5 times will be ignored (min)\n",
    "bigram_model = Phraser(phrases_model)  #phraser takes only the neccessary parts, smaller in the ram as above\n",
    "\n",
    "\n",
    "def apply_bigrams(tokens):\n",
    "    return bigram_model[tokens]\n",
    "\n",
    "\n",
    "df['ingredients_bigrams'] = df['ingredients_for_w2v'].apply(apply_bigrams)\n",
    "\n",
    "print(\"\\n--- Vorher / Nachher Vergleich ---\")\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    alt = df['ingredients_for_w2v'].iloc[i]\n",
    "    neu = df['ingredients_bigrams'].iloc[i]\n",
    "\n",
    "    if alt != neu:\n",
    "        print(f\"Alt: {alt}\")\n",
    "        print(f\"Neu: {neu}\")\n",
    "        print(\"-\" * 30)\n",
    "        count += 1\n",
    "        if count >= 5: break\n",
    "\n"
   ],
   "id": "761b0250de55babc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start bigramm modell...\n",
      "\n",
      "--- Vorher / Nachher Vergleich ---\n",
      "Alt: ['chicken', 'kosher', 'salt', 'acorn', 'squash', 'sage', 'rosemary', 'butter', 'allspice', 'crushed', 'red', 'pepper', 'flake', 'black', 'pepper', 'loaf', 'white', 'bread', 'apple', 'olive', 'oil', 'red', 'onion', 'thinly', 'apple', 'cider', 'vinegar', 'white', 'miso', 'purpose', 'flour', 'butter', 'white', 'wine', 'chicken', 'broth', 'white', 'miso', 'kosher', 'salt', 'pepper']\n",
      "Neu: ['chicken', 'kosher_salt', 'acorn_squash', 'sage_rosemary', 'butter', 'allspice', 'crushed_red', 'pepper_flake', 'black_pepper', 'loaf', 'white_bread', 'apple', 'olive_oil', 'red_onion', 'thinly', 'apple_cider', 'vinegar', 'white_miso', 'purpose_flour', 'butter', 'white_wine', 'chicken_broth', 'white_miso', 'kosher_salt', 'pepper']\n",
      "------------------------------\n",
      "Alt: ['egg', 'white', 'potato', 'kosher', 'salt', 'black', 'pepper', 'rosemary', 'thyme', 'parsley']\n",
      "Neu: ['egg_white', 'potato', 'kosher_salt', 'black_pepper', 'rosemary_thyme', 'parsley']\n",
      "------------------------------\n",
      "Alt: ['evaporated', 'milk', 'milk', 'garlic', 'powder', 'onion', 'powder', 'smoked', 'paprika', 'black', 'pepper', 'kosher', 'salt', 'cheddar', 'cream', 'cheese', 'elbow', 'macaroni']\n",
      "Neu: ['evaporated_milk', 'milk', 'garlic_powder', 'onion', 'powder', 'smoked_paprika', 'black_pepper', 'kosher_salt', 'cheddar', 'cream_cheese', 'elbow_macaroni']\n",
      "------------------------------\n",
      "Alt: ['round', 'italian', 'loaf', 'cube', 'olive', 'oil', 'sweet', 'italian', 'sausage', 'butter', 'onion', 'celery', 'rib', 'garlic', 'clove', 'egg', 'lightly', 'beaten', 'heavy', 'cream', 'turkey', 'giblet', 'stock', 'reduced', 'sodium', 'chicken', 'broth', 'parmigiano', 'reggiano', 'leaf', 'parsley', 'shallow', 'ceramic', 'glass', 'baking', 'dish']\n",
      "Neu: ['round', 'italian_loaf', 'cube', 'olive_oil', 'sweet_italian', 'sausage', 'butter', 'onion_celery', 'rib', 'garlic_clove', 'egg_lightly', 'beaten', 'heavy_cream', 'turkey_giblet', 'stock_reduced', 'sodium_chicken', 'broth', 'parmigiano_reggiano', 'leaf_parsley', 'shallow', 'ceramic_glass', 'baking_dish']\n",
      "------------------------------\n",
      "Alt: ['dark', 'brown', 'sugar', 'hot', 'water', 'bourbon', 'lemon', 'juice', 'apple', 'butter', 'orange', 'twist', 'cinnamon']\n",
      "Neu: ['dark_brown', 'sugar', 'hot_water', 'bourbon', 'lemon_juice', 'apple', 'butter', 'orange_twist', 'cinnamon']\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:21:31.545434Z",
     "start_time": "2025-12-13T14:21:30.102047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "print(\"start final word2vec training\")\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = Word2Vec(df['ingredients_bigrams'], workers=cores - 1, vector_size=200, window=10, min_count=5, sg=1)\n",
    "\n",
    "model_path = \"../data/models/recipe_word2vec.model\"\n",
    "model.save(model_path)\n",
    "print(f\"model trained and saved under: {model_path}\")\n"
   ],
   "id": "23e51dfe3f4a7919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start final word2vec training\n",
      "model trained and saved under: ../data/models/recipe_word2vec.model\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T14:21:31.606650Z",
     "start_time": "2025-12-13T14:21:31.576478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def check(term):\n",
    "    try:\n",
    "        similar = model.wv.most_similar(term, topn=5)\n",
    "        print(f\"\\nAlternativen zu '{term}'?\")\n",
    "        for item, score in similar:\n",
    "            print(f\"  -> {item} ({score:.2f})\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n❌ '{term}' kenne ich nicht.\")\n",
    "\n",
    "\n",
    "# Teste die neuen Bigrams!\n",
    "check(\"chicken\")\n",
    "check(\"beef\")\n",
    "check(\"chocolate\")\n",
    "check(\"spaghetti\")\n",
    "check(\"tomato\")\n",
    "check(\"olive\")"
   ],
   "id": "95f707cf4fff0b30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternativen zu 'chicken'?\n",
      "  -> separated_ring (0.78)\n",
      "  -> chicken_turkey (0.78)\n",
      "  -> top_round (0.78)\n",
      "  -> skinned (0.77)\n",
      "  -> chickpea_soaked (0.77)\n",
      "\n",
      "Alternativen zu 'beef'?\n",
      "  -> pork (0.85)\n",
      "  -> dark_meat (0.85)\n",
      "  -> bottle_dark (0.84)\n",
      "  -> hot_spanish (0.84)\n",
      "  -> slab (0.84)\n",
      "\n",
      "Alternativen zu 'chocolate'?\n",
      "  -> milk_chocolate (0.94)\n",
      "  -> white_chocolate (0.93)\n",
      "  -> cocoa_powder (0.91)\n",
      "  -> bar (0.91)\n",
      "  -> dark_chocolate (0.90)\n",
      "\n",
      "Alternativen zu 'spaghetti'?\n",
      "  -> rigatoni (0.93)\n",
      "  -> bucatini (0.93)\n",
      "  -> capellini (0.92)\n",
      "  -> accompaniment_parmigiano (0.92)\n",
      "  -> bucatini_spaghetti (0.91)\n",
      "\n",
      "Alternativen zu 'tomato'?\n",
      "  -> undrained (0.80)\n",
      "  -> oregano_crumbled (0.79)\n",
      "  -> eggplant (0.78)\n",
      "  -> plum_rom (0.78)\n",
      "  -> san_marzano (0.78)\n",
      "\n",
      "Alternativen zu 'olive'?\n",
      "  -> kalamata (0.86)\n",
      "  -> caper (0.80)\n",
      "  -> spanish (0.79)\n",
      "  -> kalamata_olive (0.79)\n",
      "  -> olive_tapenade (0.78)\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
